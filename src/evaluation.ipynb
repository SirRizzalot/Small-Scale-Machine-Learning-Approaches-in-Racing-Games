{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "0Y9HAhoIZJ2a"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "!apt install python-opengl\n",
        "!apt install ffmpeg\n",
        "!apt install xvfb\n",
        "!pip install pyvirtualdisplay\n",
        "!pip install pyglet==1.5.1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "GbKXjPw8fkXL"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "!pip install swig\n",
        "!pip install gymnasium[box2d]\n",
        "!pip install stable_baselines3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cUClNrpuZMH5",
        "outputId": "97734430-3614-40aa-e35f-e47d360344c4"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<pyvirtualdisplay.display.Display at 0x7f0b0073f7f0>"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Virtual Display\n",
        "from pyvirtualdisplay import Display\n",
        "import imageio\n",
        "\n",
        "virtual_display = Display(visible=0, size=(1400, 900))\n",
        "virtual_display.start()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "MRKNoOfbZOm8"
      },
      "outputs": [],
      "source": [
        "# NumPy\n",
        "import numpy as np\n",
        "\n",
        "# MatPlotLib\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "# Gym\n",
        "import gymnasium as gym\n",
        "\n",
        "# Stable Baselines\n",
        "import stable_baselines3\n",
        "from stable_baselines3 import PPO\n",
        "from stable_baselines3.common.vec_env import DummyVecEnv, VecNormalize\n",
        "\n",
        "from stable_baselines3.common.utils import set_random_seed\n",
        "from stable_baselines3.common.evaluation import evaluate_policy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y1_SpDRAV_6j"
      },
      "outputs": [],
      "source": [
        "# Define Seeded Environment Creation\n",
        "def make_seeded_env(rank: int, seed: int = 50):\n",
        "    def _init():\n",
        "        env = gym.make(\"CarRacing-v2\", continuous=True, render_mode=\"rgb_array\")\n",
        "        env = gym.wrappers.GrayScaleObservation(env)\n",
        "        env = gym.wrappers.FrameStack(env, 4)\n",
        "        env.reset(seed = seed + rank)\n",
        "        return env\n",
        "    set_random_seed(seed)\n",
        "    return _init"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wZ-mIUJWiQJ4"
      },
      "outputs": [],
      "source": [
        "# Define Unseeded Environment Creation\n",
        "def make_unseeded_env(rank: int, seed: int = 50):\n",
        "    def _init():\n",
        "        env = gym.make(\"CarRacing-v2\", continuous=True, render_mode=\"rgb_array\")\n",
        "        env = gym.wrappers.GrayScaleObservation(env)\n",
        "        env = gym.wrappers.FrameStack(env, 4)\n",
        "        env.reset(seed = np.random.randint(9999))\n",
        "        return env\n",
        "    set_random_seed(np.random.randint(9999))\n",
        "    return _init"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6Ch2pzE4iUMm"
      },
      "outputs": [],
      "source": [
        "# Define Recording Process (Adapted from Class Assignments)\n",
        "def record_video(env, agent, out_directory, fps=30):\n",
        "  images = []\n",
        "  done = [False]\n",
        "  state = vec_env.reset()\n",
        "  img = vec_env.render(mode='rgb_array')\n",
        "  images.append(img)\n",
        "  total_step = 0\n",
        "  while not any(done) and total_step <= 10000:\n",
        "    # Take the action (index) that have the maximum expected future reward given that state\n",
        "    action, _ = agent.predict(state)\n",
        "    state, reward, done, info = vec_env.step(action) # We directly put next_state = state for recording logic\n",
        "    img = vec_env.render(mode='rgb_array')\n",
        "    images.append(img)\n",
        "    total_step += 1\n",
        "  imageio.mimsave(out_directory, [np.array(img) for i, img in enumerate(images)], fps=fps)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SkJF99LSjcG1"
      },
      "source": [
        "SEEDED EVALUATION"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J6YK7Ji3fSiM"
      },
      "outputs": [],
      "source": [
        "# Make Evaluation/Recording Environment\n",
        "vec_env = DummyVecEnv([make_seeded_env(0)])\n",
        "vec_env = VecNormalize(vec_env, norm_reward=False)\n",
        "_ = vec_env.reset()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9dYBrrsQr5jj",
        "outputId": "2c2daa88-f17b-45fd-f78b-d066f81c2cba"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "677.1284952230751 237.26076344279085\n"
          ]
        }
      ],
      "source": [
        "# Evaluation\n",
        "model = PPO.load(\"ppo_carracing\")\n",
        "mean_reward, std_reward = evaluate_policy(model, vec_env, n_eval_episodes=10)\n",
        "\n",
        "print(mean_reward, std_reward)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Imbi2nYQhybo",
        "outputId": "38b2f6f5-2232-4feb-8743-fa746b31be18"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:imageio_ffmpeg:IMAGEIO FFMPEG_WRITER WARNING: input image is not divisible by macro_block_size=16, resizing from (600, 400) to (608, 400) to ensure video compatibility with most codecs and players. To prevent resizing, make your input image divisible by the macro_block_size or set the macro_block_size to 1 (risking incompatibility).\n"
          ]
        }
      ],
      "source": [
        "# Record\n",
        "record_video(vec_env, model, 'seeded_replay.mp4')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1xjtC1UkjraH"
      },
      "source": [
        "UNSEEDED EVALUATION"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q0pi4zGxjufm"
      },
      "outputs": [],
      "source": [
        "# Make Evaluation/Recording Environment\n",
        "vec_env = DummyVecEnv([make_unseeded_env(0)])\n",
        "vec_env = VecNormalize(vec_env, norm_reward=False)\n",
        "_ = vec_env.reset()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6GNca9Txjx6s",
        "outputId": "17ed4bd8-020d-4892-b712-8ba767253a4f"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/stable_baselines3/common/evaluation.py:67: UserWarning: Evaluation environment is not wrapped with a ``Monitor`` wrapper. This may result in reporting modified episode lengths and rewards, if other wrappers happen to modify these. Consider wrapping environment first with ``Monitor`` wrapper.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "591.9635081730783 211.40069599473964\n"
          ]
        }
      ],
      "source": [
        "# Evaluation\n",
        "model = PPO.load(\"ppo_carracing\")\n",
        "mean_reward, std_reward = evaluate_policy(model, vec_env, n_eval_episodes=10)\n",
        "\n",
        "print(mean_reward, std_reward)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o9R6qlpyjyr7",
        "outputId": "466d8759-f202-45b3-a9fb-53fe60702b0b"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:imageio_ffmpeg:IMAGEIO FFMPEG_WRITER WARNING: input image is not divisible by macro_block_size=16, resizing from (600, 400) to (608, 400) to ensure video compatibility with most codecs and players. To prevent resizing, make your input image divisible by the macro_block_size or set the macro_block_size to 1 (risking incompatibility).\n"
          ]
        }
      ],
      "source": [
        "# Record\n",
        "record_video(vec_env, model, 'unseeded_replay.mp4')"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
